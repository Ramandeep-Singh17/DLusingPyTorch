{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramandeep-Singh17/DLusingPyTorch/blob/main/4_pytorch_nn_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî• torch.nn Module (PyTorch)\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ What is nn Module?\n",
        "\n",
        "`torch.nn` PyTorch ka core module hai  \n",
        "jo neural networks banane ke liye ready-made tools deta hai.\n",
        "\n",
        "Simple words:\n",
        "üëâ Neural network banane ka toolkit.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Why We Use nn Module?\n",
        "\n",
        "Pehle hum manually kar rahe the:\n",
        "\n",
        "- z = w*x + b\n",
        "- activation manually\n",
        "- loss manually\n",
        "- backward manually handle\n",
        "\n",
        "Ab:\n",
        "\n",
        "nn module ye sab easy bana deta hai.\n",
        "\n",
        "‚úî Clean code  \n",
        "‚úî Less error  \n",
        "‚úî Scalable for deep networks  \n",
        "\n",
        "---\n",
        "\n",
        "## üîπ What Improvement Are We Doing?\n",
        "\n",
        "Manual math ‚Üí Structured neural network building  \n",
        "\n",
        "Hum ab:\n",
        "- Layers manually nahi likhenge\n",
        "- Built-in layers use karenge\n",
        "- Built-in activation use karenge\n",
        "- Built-in loss use karenge\n",
        "- Built-in optimizer use karenge\n",
        "\n",
        "Professional way me shift ho rahe hain üî•\n",
        "\n",
        "---\n",
        "\n",
        "# üîë Key Components of torch.nn\n",
        "\n",
        "---\n",
        "\n",
        "## 1Ô∏è‚É£ Modules (Layers)\n",
        "\n",
        "Base class:\n",
        "```\n",
        "nn.Module\n",
        "```\n",
        "\n",
        "Har neural network class isi se inherit karta hai.\n",
        "\n",
        "Example layers:\n",
        "\n",
        "- nn.Linear ‚Üí Fully connected layer  \n",
        "- nn.Conv2d ‚Üí Convolution layer  \n",
        "- nn.LSTM ‚Üí Recurrent layer  \n",
        "\n",
        "Example:\n",
        "```\n",
        "nn.Linear(in_features, out_features)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 2Ô∏è‚É£ Activation Functions\n",
        "\n",
        "Model me non-linearity add karte hain.\n",
        "\n",
        "Common activation functions:\n",
        "\n",
        "- nn.ReLU()\n",
        "- nn.Sigmoid()\n",
        "- nn.Tanh()\n",
        "- nn.Softmax(dim=1)\n",
        "- nn.LeakyReLU()\n",
        "- nn.ELU()\n",
        "\n",
        "Ye layers ke baad lagte hain.\n",
        "\n",
        "---\n",
        "\n",
        "## 3Ô∏è‚É£ Loss Functions\n",
        "\n",
        "Prediction aur actual ke beech difference measure karta hai.\n",
        "\n",
        "Common loss functions:\n",
        "\n",
        "- nn.MSELoss() ‚Üí Regression\n",
        "- nn.CrossEntropyLoss() ‚Üí Multi-class classification\n",
        "- nn.BCELoss() ‚Üí Binary classification\n",
        "- nn.BCEWithLogitsLoss() ‚Üí Stable binary classification\n",
        "- nn.NLLLoss()\n",
        "\n",
        "---\n",
        "\n",
        "## 4Ô∏è‚É£ Container Modules\n",
        "\n",
        "Layers ko stack karne ke liye.\n",
        "\n",
        "- nn.Sequential()\n",
        "\n",
        "Example:\n",
        "```\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(10, 5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(5, 1)\n",
        ")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5Ô∏è‚É£ Regularization & Utilities\n",
        "\n",
        "- nn.Dropout()\n",
        "- nn.BatchNorm1d()\n",
        "- nn.BatchNorm2d()\n",
        "\n",
        "Overfitting control karne ke liye.\n",
        "\n",
        "---\n",
        "\n",
        "# üî• Simple Hinglish Summary\n",
        "\n",
        "`torch.nn` ek complete toolkit hai neural network banane ke liye.\n",
        "\n",
        "Manual math se nikal kar  \n",
        "ab hum structured aur scalable deep learning code likhne wale hain.\n",
        "\n",
        "Ye professional deep learning ka starting point hai.\n"
      ],
      "metadata": {
        "id": "bnWFN8_5NvjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create model class\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Model(nn.Module):\n",
        "  #class yaha inheritaed hai nn.module class se\n",
        "\n",
        "  def __init__(self, num_features):\n",
        "\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(num_features, 3),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(3, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, features):\n",
        "\n",
        "    out = self.network(features)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "oJvxf-ftpdEy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t_nzgh8XNuot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataset\n",
        "features = torch.rand(10,5)\n",
        "\n",
        "# create model\n",
        "model = Model(features.shape[1])\n",
        "\n",
        "# call model for forward pass\n",
        "# model.forward(features)\n",
        "model(features)\n",
        "# yaha forward methoad automatic kaam karta hai"
      ],
      "metadata": {
        "id": "I_Tbf5p6sQQI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6749c84-1855-479d-9fd2-fcc09afec46a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4676],\n",
              "        [0.4107],\n",
              "        [0.3660],\n",
              "        [0.4017],\n",
              "        [0.3994],\n",
              "        [0.4001],\n",
              "        [0.4827],\n",
              "        [0.4211],\n",
              "        [0.4338],\n",
              "        [0.4385]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show model weights\n",
        "model.network[2].weight"
      ],
      "metadata": {
        "id": "Kf6yPbtBPvCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4491ce32-46bc-47c8-bac8-00ee9d0b8d29"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.3173, -0.4512, -0.2821]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "# for visualization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcER5vK3saCz",
        "outputId": "d21cf249-fc9e-4dca-b92e-db6d8bc8cb15"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.12/dist-packages (1.8.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "summary(model, input_size=(10, 5))"
      ],
      "metadata": {
        "id": "ah9VjT_dxiJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f702f721-09fe-487c-e6a1-34ffc5bd7fd5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Model                                    [10, 1]                   --\n",
              "‚îú‚îÄSequential: 1-1                        [10, 1]                   --\n",
              "‚îÇ    ‚îî‚îÄLinear: 2-1                       [10, 3]                   18\n",
              "‚îÇ    ‚îî‚îÄReLU: 2-2                         [10, 3]                   --\n",
              "‚îÇ    ‚îî‚îÄLinear: 2-3                       [10, 1]                   4\n",
              "‚îÇ    ‚îî‚îÄSigmoid: 2-4                      [10, 1]                   --\n",
              "==========================================================================================\n",
              "Total params: 22\n",
              "Trainable params: 22\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.MEGABYTES): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7AbUHThPxpIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üî• torch.optim Module (Optimizer in PyTorch)\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ What is torch.optim?\n",
        "\n",
        "`torch.optim` PyTorch ka module hai  \n",
        "jo model ke **weights update karne ka kaam karta hai** during training.\n",
        "\n",
        "Simple words:\n",
        "üëâ Ye decide karta hai weight kaise update honge.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Why We Need Optimizer?\n",
        "\n",
        "Training ka main goal hota hai:\n",
        "\n",
        "Loss ko kam karna.\n",
        "\n",
        "Loss kam karne ke liye:\n",
        "- Gradient milta hai (Autograd se)\n",
        "- Us gradient ke basis pe weights update karne hote hain\n",
        "\n",
        "Optimizer hi ye update karta hai.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Training Flow Me Role\n",
        "\n",
        "1. Forward pass\n",
        "2. Loss calculate\n",
        "3. Backward ‚Üí gradient milta hai\n",
        "4. Optimizer ‚Üí weight update karta hai\n",
        "\n",
        "Without optimizer:\n",
        "‚ùå Gradients mil jayenge  \n",
        "‚ùå But weights change nahi honge  \n",
        "\n",
        "---\n",
        "\n",
        "# üîë Common Optimizers\n",
        "\n",
        "- optim.SGD() ‚Üí Basic Gradient Descent\n",
        "- optim.Adam() ‚Üí Most commonly used\n",
        "- optim.RMSprop()\n",
        "- optim.Adagrad()\n",
        "\n",
        "Example:\n",
        "\n",
        "```\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üîπ model.parameters() Kya Hai?\n",
        "\n",
        "```\n",
        "model.parameters()\n",
        "```\n",
        "\n",
        "Ye model ke saare trainable parameters return karta hai:\n",
        "\n",
        "‚úî Weights  \n",
        "‚úî Biases  \n",
        "\n",
        "Optimizer inhe update karta hai.\n",
        "\n",
        "---\n",
        "\n",
        "## üîπ Parameters Kya Hote Hain?\n",
        "\n",
        "Har layer me:\n",
        "\n",
        "- Weight matrix\n",
        "- Bias vector\n",
        "\n",
        "Example:\n",
        "nn.Linear(2, 1)\n",
        "\n",
        "Isme:\n",
        "- Weight = 2 values\n",
        "- Bias = 1 value\n",
        "\n",
        "Ye sab optimizer update karega.\n",
        "\n",
        "---\n",
        "\n",
        "# üîπ Optimizer Ka Kaam Internally\n",
        "\n",
        "Update rule (simple SGD):\n",
        "\n",
        "W = W - learning_rate √ó gradient\n",
        "\n",
        "Learning rate decide karta hai:\n",
        "- Kitna bada step lena hai\n",
        "\n",
        "---\n",
        "\n",
        "# üîπ Learning Rate (Very Important)\n",
        "\n",
        "- lr chota ‚Üí training slow\n",
        "- lr bada ‚Üí training unstable\n",
        "\n",
        "Example:\n",
        "\n",
        "```\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üîπ Full Training Code Flow\n",
        "\n",
        "```\n",
        "optimizer.zero_grad()\n",
        "output = model(x)\n",
        "loss = criterion(output, y)\n",
        "loss.backward()\n",
        "optimizer.step()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üî• Hinglish Final Understanding\n",
        "\n",
        "Autograd gradient deta hai.  \n",
        "Optimizer un gradients ko use karke weights update karta hai.  \n",
        "\n",
        "Simple bolu to:\n",
        "Gradient batata hai kidhar jaana hai,  \n",
        "Optimizer step lekar waha le jaata hai.\n"
      ],
      "metadata": {
        "id": "ZyfZCzFiVOea"
      }
    }
  ]
}