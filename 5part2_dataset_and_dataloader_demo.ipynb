{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramandeep-Singh17/DLusingPyTorch/blob/main/5part2_dataset_and_dataloader_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ”¥ Recap + Why Dataset & DataLoader Needed\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ ğŸ” Recap (Flow till now)\n",
        "\n",
        "1. Tensors â†’ Data ko numerical form me store kiya  \n",
        "2. Autograd â†’ Automatic gradients (derivatives)  \n",
        "3. nn Module â†’ Neural network easily build kiya  \n",
        "4. Training Pipeline â†’ forward â†’ loss â†’ backward â†’ update  \n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ Abhi hum kya kar rahe the?\n",
        "\n",
        "Hum **Batch Gradient Descent** use kar rahe the:\n",
        "\n",
        "ğŸ‘‰ Pure dataset ek saath use karke update\n",
        "\n",
        "---\n",
        "\n",
        "## âŒ Problem with Batch Gradient Descent\n",
        "\n",
        "1. Memory inefficient  \n",
        "   â†’ Large dataset RAM/GPU me fit nahi hota  \n",
        "\n",
        "2. Slow convergence  \n",
        "   â†’ Har update ke liye poora data use ho raha hai (slow learning)\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ Solution â†’ Mini-Batch Gradient Descent\n",
        "\n",
        "ğŸ‘‰ Data ko chhote batches me tod dete hain\n",
        "\n",
        "Example:\n",
        "1000 rows â†’ batch size = 100  \n",
        "â†’ 10 batches  \n",
        "\n",
        "Ab:\n",
        "- Har batch ke baad update  \n",
        "- Faster + efficient  \n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¹ Tumne kya kiya (Manual Mini-Batch Code)\n",
        "\n",
        "Tumne manually:\n",
        "\n",
        "- start_idx, end_idx use kiya  \n",
        "- slicing se batch banaya  \n",
        "- loop chalaya  \n",
        "\n",
        "âœ” Concept correct hai  \n",
        "âŒ But scalable nahi hai  \n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”´ Problems with Manual Approach\n",
        "\n",
        "## 1. No Standard Interface for Data\n",
        "\n",
        "Har baar:\n",
        "- alag tareeke se data load karna padta hai  \n",
        "- koi fixed structure nahi  \n",
        "\n",
        "ğŸ‘‰ Messy code\n",
        "\n",
        "---\n",
        "\n",
        "## 2. No Easy Way to Apply Transformations\n",
        "\n",
        "Real-world me:\n",
        "\n",
        "- image resize karna\n",
        "- normalization\n",
        "- augmentation\n",
        "\n",
        "Manual code me:\n",
        "âŒ Hard to manage\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Shuffling & Sampling Problem\n",
        "\n",
        "Training me:\n",
        "\n",
        "- data shuffle hona chahiye\n",
        "- random sampling hona chahiye\n",
        "\n",
        "Manual me:\n",
        "âŒ khud likhna padega (error-prone)\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Batch Management & Parallelization\n",
        "\n",
        "- batch banana manually\n",
        "- multi-core loading nahi\n",
        "- slow data pipeline\n",
        "\n",
        "ğŸ‘‰ Large scale DL me fail ho jayega\n",
        "\n",
        "---\n",
        "\n",
        "# âŒ Final Problem\n",
        "\n",
        "ğŸ‘‰ Ye approach scalable nahi hai  \n",
        "ğŸ‘‰ Real-world deep learning me use nahi hota  \n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¥ Solution â†’ Dataset + DataLoader\n",
        "\n",
        "In sab problems ko solve karne ke liye:\n",
        "\n",
        "ğŸ‘‰ PyTorch deta hai:\n",
        "\n",
        "- Dataset â†’ data ko structure deta hai  \n",
        "- DataLoader â†’ batching, shuffle, fast loading  \n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¥ Hinglish Final Understanding\n",
        "\n",
        "Batch gradient descent slow aur memory heavy tha  \n",
        "isliye hum mini-batch use kar rahe hain  \n",
        "\n",
        "Par manual batching scalable nahi hai  \n",
        "isliye PyTorch me Dataset aur DataLoader use karte hain  \n",
        "jo data handling ko easy, fast aur professional bana deta hai\n"
      ],
      "metadata": {
        "id": "dupG5y1ZdJEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Next part**"
      ],
      "metadata": {
        "id": "s6mlONGAdL5m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TgAOwS2a3Keb"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ”¥ Dataset & DataLoader (PyTorch)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Dataset Kya Hai?\n",
        "\n",
        "Dataset ek **blueprint / structure** hai  \n",
        "jo batata hai:\n",
        "\n",
        "ğŸ‘‰ Data kaha hai  \n",
        "ğŸ‘‰ Data kaise load hoga  \n",
        "ğŸ‘‰ Data kaise return hoga  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Dataset = Abstract Class\n",
        "\n",
        "- Direct use nahi karte  \n",
        "- Apni custom class banate hain  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Dataset ke 3 Important Methods\n",
        "\n",
        "### 1. __init__()\n",
        "ğŸ‘‰ Data load kaise hoga\n",
        "\n",
        "Example:\n",
        "- CSV read\n",
        "- images load\n",
        "- arrays store\n",
        "\n",
        "---\n",
        "\n",
        "### 2. __len__()\n",
        "ğŸ‘‰ Total samples batata hai (NOT batches)\n",
        "\n",
        "Example:\n",
        "1000 rows â†’ len = 1000\n",
        "\n",
        "---\n",
        "\n",
        "### 3. __getitem__(index)\n",
        "ğŸ‘‰ Kisi bhi index ka data return karta hai\n",
        "\n",
        "Example:\n",
        "dataset[5] â†’ (x, y)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¥ Example Samajh\n",
        "\n",
        "Data:\n",
        "[ (2,0), (5,1), (7,0), (9,1) ]\n",
        "\n",
        "- len() â†’ 4  \n",
        "- getitem(2) â†’ (7,0)\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¥ DataLoader Kya Hai?\n",
        "\n",
        "DataLoader = Dataset ka helper\n",
        "\n",
        "ğŸ‘‰ Data ko:\n",
        "- Batch me convert karta hai  \n",
        "- Shuffle karta hai  \n",
        "- Fast loading karta hai  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ DataLoader Flow (Step-by-Step)\n",
        "\n",
        "Maan lo:\n",
        "\n",
        "data = [0,1,2,3,4,5,6,7,8,9]  \n",
        "batch_size = 2  \n",
        "shuffle = True  \n",
        "\n",
        "---\n",
        "\n",
        "### Step 1: Shuffle (Sampler)\n",
        "\n",
        "Original:\n",
        "0 1 2 3 4 5 6 7 8 9  \n",
        "\n",
        "Shuffled:\n",
        "4 6 1 3 7 8 2 0 9 5  \n",
        "\n",
        "---\n",
        "\n",
        "### Step 2: Batches me divide\n",
        "\n",
        "[4,6]  \n",
        "[1,3]  \n",
        "[7,8]  \n",
        "[2,0]  \n",
        "[9,5]  \n",
        "\n",
        "---\n",
        "\n",
        "### Step 3: Dataset se data fetch\n",
        "\n",
        "dataset[4], dataset[6] â†’ batch  \n",
        "\n",
        "---\n",
        "\n",
        "### Step 4: Combine (collate_fn)\n",
        "\n",
        "ğŸ‘‰ Batch ready  \n",
        "\n",
        "---\n",
        "\n",
        "### Step 5: Training loop me use\n",
        "\n",
        "for batch in dataloader:\n",
        "    model(batch)\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”´ Important Points\n",
        "\n",
        "- Dataset â†’ data ka source  \n",
        "- DataLoader â†’ data ka manager  \n",
        "- len() â†’ total samples (NOT batches)  \n",
        "- Shuffling â†’ DataLoader karta hai  \n",
        "- Batching â†’ DataLoader karta hai  \n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¥ Final Hinglish Understanding\n",
        "\n",
        "Dataset batata hai data kaha se aur kaise aayega  \n",
        "DataLoader us data ko shuffle karke batches me model tak pahunchata hai  \n",
        "\n",
        "ğŸ‘‰ Dataset = \"data dene wala\"  \n",
        "ğŸ‘‰ DataLoader = \"data manage karne wala\"\n"
      ],
      "metadata": {
        "id": "OCRFIGa2dbBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a synthetic classification dataset using sklearn\n",
        "X, y = make_classification(\n",
        "    n_samples=10,       # Number of samples\n",
        "    n_features=2,       # Number of features\n",
        "    n_informative=2,    # Number of informative features\n",
        "    n_redundant=0,      # Number of redundant features\n",
        "    n_classes=2,        # Number of classes\n",
        "    random_state=42     # For reproducibility\n",
        ")"
      ],
      "metadata": {
        "id": "aqEej4GC3UyT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WywhcnAj3Yec",
        "outputId": "c592264e-d395-4417-8dba-d04c3594e0a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.06833894, -0.97007347],\n",
              "       [-1.14021544, -0.83879234],\n",
              "       [-2.8953973 ,  1.97686236],\n",
              "       [-0.72063436, -0.96059253],\n",
              "       [-1.96287438, -0.99225135],\n",
              "       [-0.9382051 , -0.54304815],\n",
              "       [ 1.72725924, -1.18582677],\n",
              "       [ 1.77736657,  1.51157598],\n",
              "       [ 1.89969252,  0.83444483],\n",
              "       [-0.58723065, -1.97171753]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBb4gaS_3cYe",
        "outputId": "51705599-9a00-4c1e-c211-0166a6fd4299"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAAejfi23fkA",
        "outputId": "28b9e206-c39e-4e10-8763-663f1f3c78d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape\n",
        "#target col"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZI0UX7R3f4H",
        "outputId": "ee05f12b-69eb-4c00-99db-5bc0c94f79fc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to PyTorch tensors\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.long)"
      ],
      "metadata": {
        "id": "hm8_V0OQ3hby"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8b5_oEF8ejn",
        "outputId": "def7904d-c527-46de-f87a-3ce568cf9655"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0683, -0.9701],\n",
              "        [-1.1402, -0.8388],\n",
              "        [-2.8954,  1.9769],\n",
              "        [-0.7206, -0.9606],\n",
              "        [-1.9629, -0.9923],\n",
              "        [-0.9382, -0.5430],\n",
              "        [ 1.7273, -1.1858],\n",
              "        [ 1.7774,  1.5116],\n",
              "        [ 1.8997,  0.8344],\n",
              "        [-0.5872, -1.9717]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pkxag9k-8gQh",
        "outputId": "57997732-5e96-426d-e22b-28b64fdaa309"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 0, 0, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "7nm0KeiA3lxj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  #inherit from dataset\n",
        "\n",
        "  def __init__(self, features, labels):\n",
        "\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self):\n",
        "\n",
        "    return self.features.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    return self.features[index], self.labels[index]"
      ],
      "metadata": {
        "id": "_WdH2NCq4zLD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(X, y)"
      ],
      "metadata": {
        "id": "mbEXolf88_zV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCMLR4fH9Fvo",
        "outputId": "d77c811e-a15b-4ee6-c808-49be6625dbc4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUpEROQr9NXs",
        "outputId": "96d10e3e-aa07-4c72-9c54-36f99ec33ad6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-2.8954,  1.9769]), tensor(0))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=False)\n",
        "#shuffle true karne se randomly ban a hai and agar false karenge tab order me batches banenge  2 points ko mila ke 1st wala banega"
      ],
      "metadata": {
        "id": "0v4w5dki9QDu"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_features, batch_labels in dataloader:\n",
        "\n",
        "  print(batch_features)\n",
        "  print(batch_labels)\n",
        "  print(\"-\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AE9Ji0l9gVB",
        "outputId": "bde883fc-783c-4ab8-ab11-0fe87c29dac6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0683, -0.9701],\n",
            "        [-1.1402, -0.8388]])\n",
            "tensor([1, 0])\n",
            "--------------------------------------------------\n",
            "tensor([[-2.8954,  1.9769],\n",
            "        [-0.7206, -0.9606]])\n",
            "tensor([0, 0])\n",
            "--------------------------------------------------\n",
            "tensor([[-1.9629, -0.9923],\n",
            "        [-0.9382, -0.5430]])\n",
            "tensor([0, 1])\n",
            "--------------------------------------------------\n",
            "tensor([[ 1.7273, -1.1858],\n",
            "        [ 1.7774,  1.5116]])\n",
            "tensor([1, 1])\n",
            "--------------------------------------------------\n",
            "tensor([[ 1.8997,  0.8344],\n",
            "        [-0.5872, -1.9717]])\n",
            "tensor([1, 0])\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ“¦ 1. Transformations (Dataset me kaise use hote hain)**"
      ],
      "metadata": {
        "id": "naFl9Zggk5pQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ”¥ Transformations in Dataset\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Problem (Manual Approach)\n",
        "\n",
        "Manual batching me:\n",
        "- Image resize\n",
        "- Normalization\n",
        "- Augmentation\n",
        "\n",
        "ye sab karna mushkil hota hai âŒ\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Solution (Dataset me)\n",
        "\n",
        "Dataset ke `__getitem__()` me hi transformation likh dete hain\n",
        "\n",
        "Example:\n",
        "```\n",
        "def __getitem__(self, index):\n",
        "    x = self.X[index]\n",
        "    y = self.y[index]\n",
        "\n",
        "    x = transform(x)   # yaha transformation\n",
        "\n",
        "    return x, y\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¥ Hinglish Samajh\n",
        "\n",
        "Manual code me transformation manage karna tough tha  \n",
        "But Dataset me `getitem` ke andar likh do â†’ automatically har sample pe apply ho jayega\n"
      ],
      "metadata": {
        "id": "I09n__XTk9JD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zj4MdNzp9riC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**âš¡ 2. Parallelization (num_workers)**\n",
        "\n",
        "---\n",
        "# ğŸ”¥ Parallel Data Loading (num_workers)\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Problem\n",
        "\n",
        "Abhi tak:\n",
        "ğŸ‘‰ Data sequential load ho raha tha  \n",
        "ğŸ‘‰ Slow training âŒ\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Solution\n",
        "\n",
        "Use:\n",
        "```\n",
        "DataLoader(..., num_workers=4)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Kaise kaam karta hai?\n",
        "\n",
        "- Multiple workers (CPU processes) ban jate hain\n",
        "- Har worker alag batch load karta hai\n",
        "\n",
        "Example:\n",
        "\n",
        "Worker 1 â†’ Batch 1  \n",
        "Worker 2 â†’ Batch 2  \n",
        "Worker 3 â†’ Batch 3  \n",
        "Worker 4 â†’ Batch 4  \n",
        "\n",
        "ğŸ‘‰ Parallel loading = faster training ğŸš€\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¥ Hinglish Samajh\n",
        "\n",
        "Pehle ek hi banda data load kar raha tha (slow)  \n",
        "Ab 4 bande ek saath kaam kar rahe hain (fast)\n",
        "\n"
      ],
      "metadata": {
        "id": "OKmvtxNElB76"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WtvTVYIdlGCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ² 3. Sampler (Shuffle & Custom Sampling)**"
      ],
      "metadata": {
        "id": "c3_xOppdlb7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ”¥ Sampler in DataLoader\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ What is Sampler?\n",
        "\n",
        "Sampler decide karta hai:\n",
        "ğŸ‘‰ Data kis order me aayega\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Types\n",
        "\n",
        "### 1. SequentialSampler\n",
        "- Order same rehta hai\n",
        "- shuffle=False\n",
        "\n",
        "Example:\n",
        "0 1 2 3 4 5 ...\n",
        "\n",
        "---\n",
        "\n",
        "### 2. RandomSampler\n",
        "- Data random order me aata hai\n",
        "- shuffle=True\n",
        "\n",
        "Example:\n",
        "4 1 7 2 0 5 ...\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Why Shuffle?\n",
        "\n",
        "- Model overfit na kare order pe\n",
        "- Better learning\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Custom Sampler (Important)\n",
        "\n",
        "Use case:\n",
        "ğŸ‘‰ Imbalanced dataset\n",
        "\n",
        "Example:\n",
        "- Class A â†’ 99%\n",
        "- Class B â†’ 1%\n",
        "\n",
        "Problem:\n",
        "Model biased ho jayega âŒ\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Solution\n",
        "\n",
        "Custom sampler use karke:\n",
        "ğŸ‘‰ Rare class ko zyada sample kara sakte hain\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¥ Hinglish Samajh\n",
        "\n",
        "Sampler decide karta hai data ka order  \n",
        "Shuffle=True â†’ random learning  \n",
        "Custom sampler â†’ imbalance problem solve\n"
      ],
      "metadata": {
        "id": "MPgmOjGwlqH1"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ec8uLnf4lcg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ğŸ§© 4. collate_fn (Batch banane ka logic)**"
      ],
      "metadata": {
        "id": "NT4b8bY7l1PZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ”¥ collate_fn in DataLoader\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ What is collate_fn?\n",
        "\n",
        "collate_fn decide karta hai:\n",
        "ğŸ‘‰ Multiple samples ko combine karke batch kaise banega\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Default Behavior\n",
        "\n",
        "- Simply stack karta hai tensors\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Problem\n",
        "\n",
        "Text data:\n",
        "\n",
        "[1,2,3]  \n",
        "[4,5]  \n",
        "[6,7,8,9]  \n",
        "\n",
        "ğŸ‘‰ Length different âŒ\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Solution â†’ Padding\n",
        "\n",
        "```\n",
        "[1,2,3,0]  \n",
        "[4,5,0,0]  \n",
        "[6,7,8,9]\n",
        "```\n",
        "\n",
        "ğŸ‘‰ Same length bana diya\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¹ Custom collate_fn\n",
        "\n",
        "- Padding\n",
        "- Custom batching\n",
        "- Complex data handle\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”¥ Hinglish Samajh\n",
        "\n",
        "collate_fn batch banata hai  \n",
        "Agar data unequal ho â†’ padding use karke equal karta hai\n"
      ],
      "metadata": {
        "id": "w-ecfNQjmAYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_ZAVWxKBmGIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**âš™ï¸ 5. Important Parameters of DataLoader**"
      ],
      "metadata": {
        "id": "mR8kP_LimH9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ”¥ DataLoader Important Parameters\n",
        "\n",
        "---\n",
        "\n",
        "## 1ï¸âƒ£ dataset (mandatory)\n",
        "\n",
        "- Data source\n",
        "- Custom Dataset hona chahiye\n",
        "\n",
        "---\n",
        "\n",
        "## 2ï¸âƒ£ batch_size\n",
        "\n",
        "- Kitne samples ek batch me\n",
        "\n",
        "Example:\n",
        "batch_size = 32\n",
        "\n",
        "---\n",
        "\n",
        "## 3ï¸âƒ£ shuffle\n",
        "\n",
        "- True â†’ data random\n",
        "- False â†’ sequential\n",
        "\n",
        "---\n",
        "\n",
        "## 4ï¸âƒ£ num_workers\n",
        "\n",
        "- Parallel loading\n",
        "\n",
        "Example:\n",
        "num_workers=4 â†’ 4 workers\n",
        "\n",
        "---\n",
        "\n",
        "## 5ï¸âƒ£ pin_memory\n",
        "\n",
        "- GPU transfer fast karta hai\n",
        "\n",
        "Used when:\n",
        "CUDA (GPU) use ho raha ho\n",
        "\n",
        "---\n",
        "\n",
        "## 6ï¸âƒ£ drop_last\n",
        "#genrally drop last ko false rakhte hai taki last wala remove na ho but last wala remove karne se wo hat jata hai\n",
        "\n",
        "- Last incomplete batch drop karta hai\n",
        "\n",
        "Example:\n",
        "100 samples, batch=32  \n",
        "â†’ last 4 drop ho jayenge\n",
        "\n",
        "---\n",
        "\n",
        "## 7ï¸âƒ£ collate_fn\n",
        "\n",
        "- Custom batch logic\n",
        "- Padding, etc.\n",
        "\n",
        "---\n",
        "\n",
        "## 8ï¸âƒ£ sampler\n",
        "\n",
        "- Custom sampling strategy\n",
        "\n",
        "---\n",
        "\n",
        "# ğŸ”¥ Final Hinglish Summary\n",
        "\n",
        "Dataset â†’ data deta hai  \n",
        "DataLoader â†’ batching, shuffle, speed handle karta hai  \n",
        "\n",
        "Ye sab milke deep learning pipeline ko scalable banate hain ğŸš€\n"
      ],
      "metadata": {
        "id": "f3WwCwV9mPMC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QcNkF3e8mODD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}